{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mondrian Multidimensional K-Anonimity\n",
    "**Authors:** Giacomo Garbarino S4545532 - Manuel Parmiggiani S4701853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global variables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary column name -> column type\n",
    "column_type_dict = {}\n",
    "# dictionary element -> hierarchy of that element\n",
    "hierarchy_dict = {}\n",
    "# value of K\n",
    "K = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a DataFrame, returns the subset of its columns that are Quasi Identifiers columns :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_qi_columns(df):\n",
    "    \n",
    "    columns = df.columns.tolist()\n",
    "    \n",
    "    for column in columns:\n",
    "        if column not in column_type_dict:\n",
    "            columns.remove(column)\n",
    "            continue\n",
    "        if column_type_dict[column] not in [\"NUMERICAL\",\"CATEGORICAL\"]:\n",
    "            columns.remove(column)\n",
    "    \n",
    "    return columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a DataFrame (group) the column with the highest cardinality :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_column(group, columns):\n",
    "    \n",
    "    cardinality_dict = {column : len(np.unique(group[column])) for column in columns}\n",
    "    split_column = max(cardinality_dict, key = cardinality_dict.get)\n",
    "    \n",
    "    return split_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a list of values, returns the nearest to their mean :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_threshold(values):\n",
    "    \n",
    "    mean = round(sum(values)/len(values))\n",
    "    threshold = min(values, key = lambda x : abs(x-mean))\n",
    "    \n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a list of values, returns an interval that contains all of them :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interval(values):\n",
    "    \n",
    "    interval_string = \"[\" + str(min(values)) + \"-\" + str(max(values)) + \"]\"\n",
    "    \n",
    "    return interval_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a list of labels (intended as labels of nodes of the hierarchy tree), returns their first common ancestor : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upper_bound(labels):\n",
    "    \n",
    "    first_label = labels[0]\n",
    "    \n",
    "    # for each value in the hierarchy of the first label...\n",
    "    for elem in hierarchy_dict[first_label]:\n",
    "        is_elem_in_common = True\n",
    "        for another_label in labels[1:]:\n",
    "            # ...chek if all of the other labels have that value in their hierarchies\n",
    "            if elem not in hierarchy_dict[another_label]:\n",
    "                is_elem_in_common = False\n",
    "                break\n",
    "        # the first one in common is the correct one, so it's returned\n",
    "        # (always found if the hierarchy.txt file is well defined)\n",
    "        if is_elem_in_common:\n",
    "            return elem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an element of a hierarchy, it returns all of its direct children nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children(element):\n",
    "    \n",
    "    children_list = []\n",
    "    \n",
    "    for key in hierarchy_dict:\n",
    "        hierarchy = hierarchy_dict[key]\n",
    "        if element not in hierarchy:\n",
    "            continue\n",
    "        # for each hierarchy containing the element...\n",
    "        for e in hierarchy:\n",
    "            # ...find the position of the element...\n",
    "            if e == element :\n",
    "                # ...and add the previous one (that is a child node of the current one) to the children list\n",
    "                child = hierarchy[hierarchy.index(element)-1]\n",
    "                if hierarchy.index(element) > hierarchy.index(child):\n",
    "                    children_list.append(child)\n",
    "                break\n",
    "\n",
    "    return np.unique(children_list).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an element, returns its ancestor (chosen among a list of possible ones) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ancestor_of(element, possible_ancestors_list):\n",
    "    \n",
    "    # only one ancestor in the list is the right one, so the first one found is returned\n",
    "    for elem in hierarchy_dict[element]:\n",
    "        if elem in possible_ancestors_list:\n",
    "            return elem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits a group of rows in 2 or more sub-groups, according to the values they have for a given split column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_column(group, split_column):\n",
    "    \n",
    "    global column_type_dict\n",
    "    \n",
    "    if column_type_dict[split_column] == \"NUMERICAL\":\n",
    "        # a threshold is calulated in order to split the group in two\n",
    "        threshold = get_numerical_threshold(group[split_column].tolist())\n",
    "        group1 = group[group[split_column] > threshold]\n",
    "        group2 = group[group[split_column] < threshold]\n",
    "        # the leftover is divided among the two groups\n",
    "        leftover = group[group[split_column] == threshold]\n",
    "        for _,row in leftover.iterrows():\n",
    "            if (len(group1) < len(group2)):\n",
    "                group1 = group1.append(row)\n",
    "            else :\n",
    "                group2 = group2.append(row)\n",
    "        return [group1, group2]\n",
    "    \n",
    "    else:\n",
    "        # the upper bound for the column values is calculated...\n",
    "        threshold = get_upper_bound(group[split_column].tolist())\n",
    "        # ...and the children nodes of the upper bound are extracted\n",
    "        children_list = get_children(threshold)\n",
    "        # if the upper bound is a leaf, then the group itself it's already minimal for this column\n",
    "        if len(children_list) == 0:\n",
    "            return [group]\n",
    "        \n",
    "        new_groups_dict = {}\n",
    "        leftover = []\n",
    "        i=0\n",
    "        # assigning each column to the group it will belong (one group for each children node)\n",
    "        for _,row in group.iterrows():\n",
    "            key = get_ancestor_of(row[split_column], children_list)\n",
    "            if key == None:\n",
    "                leftover.append(i)\n",
    "                i = i+1\n",
    "                continue\n",
    "            if key not in new_groups_dict:\n",
    "                new_groups_dict[key] = []\n",
    "            new_groups_dict[key].append(i)\n",
    "            i = i+1\n",
    "        # elements in 'leftover' are the ones with the column value equal to the upper bound\n",
    "        # since they can fit in each of the new groups, they are distribuited among them...\n",
    "        for index in leftover:\n",
    "            length_dict = {key : len(new_groups_dict[key]) for key in new_groups_dict}\n",
    "            # ...following the rule of being assigned to the smallest group each\n",
    "            lowest = min(length_dict, key = length_dict.get)\n",
    "            new_groups_dict[lowest].append(index)\n",
    "            \n",
    "        new_groups_list = []\n",
    "        for child in children_list:\n",
    "            # the new group is created extracting the rows from the original group...\n",
    "            if child in new_groups_dict:\n",
    "                new_group = group.iloc[new_groups_dict[child]]\n",
    "                if not new_group.empty:\n",
    "                    # ...then is added to the list cotaining all of the groups\n",
    "                    new_groups_list.append(new_group)\n",
    "                \n",
    "        return new_groups_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits a given DataFrame into groups of rows :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    \n",
    "    global K\n",
    "    columns = select_qi_columns(df)\n",
    "    group_list = []\n",
    "    \n",
    "    while columns:\n",
    "        split_column = get_split_column(df, columns)\n",
    "        new_groups = split_by_column(df, split_column)\n",
    "        \n",
    "        # checks over the list of new groups :\n",
    "        #---the list must be not empty\n",
    "        #---all of the new groups must contain at least K rows\n",
    "        #---none of the new groups can be equal to the original one\n",
    "        \n",
    "        # if all of these requirements are satisfied...\n",
    "        if len(new_groups) > 0 and np.all([len(g.index) >= K for g in new_groups]) and np.all([not df.equals(g) for g in new_groups]):\n",
    "            # ...the new groups are added to the tail of the group list\n",
    "            for new_group in new_groups:\n",
    "                new_split = split(new_group)\n",
    "                if type(new_split) == list:\n",
    "                    group_list.extend(new_split)\n",
    "                else:\n",
    "                    group_list.append(new_split)\n",
    "            return group_list\n",
    "        # if not...\n",
    "        else:\n",
    "            # ...no more splits are possible for the chosen split_column\n",
    "            columns.remove(split_column)\n",
    "            continue\n",
    "        break\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anonymizes a list of groups and returns the final anonymized DataFrame :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize(group_list):\n",
    "    \n",
    "    final_group_list = copy.deepcopy(group_list)\n",
    "    \n",
    "    # for each group...\n",
    "    for group in final_group_list:\n",
    "        \n",
    "        # ...and for each column...\n",
    "        for column in group.columns:\n",
    "            \n",
    "            # ...the value of each row of the group for that column is replaced with a\n",
    "            #    new value representing all of that column values of the currrent group\n",
    "            \n",
    "            if column_type_dict[column] == \"NUMERICAL\":\n",
    "                group.loc[:, column] = create_interval(group[column].tolist())\n",
    "                \n",
    "            elif column_type_dict[column] == \"CATEGORICAL\":\n",
    "                new_value = get_upper_bound(group[column].tolist())\n",
    "                if len(np.unique(group[column])) == 1 and len(hierarchy_dict[new_value]) > 1:\n",
    "                    new_value = hierarchy_dict[new_value][1]\n",
    "                group.loc[:, column] = new_value\n",
    "    \n",
    "    final_df = pd.concat(final_group_list)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Age': 'NUMERICAL', 'Birthplace': 'CATEGORICAL', 'Occupation': 'CATEGORICAL', 'Annual Income': 'SD'}\n"
     ]
    }
   ],
   "source": [
    "column_file = open(\"Data/column_types.txt\")\n",
    "for line in column_file:\n",
    "    values_list = line.split(\",\")\n",
    "    #the last element of each row may contain a special \\n character we want to remove\n",
    "    first = values_list[0]\n",
    "    last = values_list.pop()\n",
    "    if (last[len(last) - 1] == \"\\n\"):\n",
    "        last = last[:len(last) - 1]\n",
    "    #then the formatted value is re-added to the list\n",
    "    column_type_dict[first] = last\n",
    "\n",
    "print(column_type_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cuba': ['Cuba', 'North America', 'America', 'World'], 'North America': ['North America', 'America', 'World'], 'America': ['America', 'World'], 'World': ['World'], 'Jamaica': ['Jamaica', 'North America', 'America', 'World'], 'Canada': ['Canada', 'North America', 'America', 'World'], 'Columbia': ['Columbia', 'South America', 'America', 'World'], 'South America': ['South America', 'America', 'World'], 'Ecuador': ['Ecuador', 'South America', 'America', 'World'], 'England': ['England', 'Central Europe', 'Europe', 'World'], 'Central Europe': ['Central Europe', 'Europe', 'World'], 'Europe': ['Europe', 'World'], 'Portugal': ['Portugal', 'West Europe', 'Europe', 'World'], 'West Europe': ['West Europe', 'Europe', 'World'], 'Ireland': ['Ireland', 'West Europe', 'Europe', 'World'], 'Japan': ['Japan', 'East Asia', 'Asia', 'World'], 'East Asia': ['East Asia', 'Asia', 'World'], 'Asia': ['Asia', 'World'], 'Teacher': ['Teacher', 'Scholastic', 'Any'], 'Scholastic': ['Scholastic', 'Any'], 'Any': ['Any'], 'University Teacher': ['University Teacher', 'Scholastic', 'Any'], 'Post Office': ['Post Office', 'State', 'Any'], 'State': ['State', 'Any'], 'Police': ['Police', 'State', 'Any'], 'Office': ['Office', 'Private', 'Any'], 'Private': ['Private', 'Any']}\n"
     ]
    }
   ],
   "source": [
    "hierarchy_file = open(\"Data/hierarchies.txt\")\n",
    "for line in hierarchy_file:\n",
    "    if (line[0] == '-'):\n",
    "        continue\n",
    "    values_list = line.split(\",\")\n",
    "    #the last element of each row may contain a special \\n character we want to remove\n",
    "    last = values_list.pop()\n",
    "    if (last[len(last) - 1] == \"\\n\"):\n",
    "        last = last[:len(last) - 1]\n",
    "    #then the formatted value is re-added to the list\n",
    "    values_list.append(last)\n",
    "    for index,value in enumerate(values_list):\n",
    "        hierarchy_dict[value] = values_list[index:]\n",
    "    \n",
    "print (hierarchy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age     Birthplace          Occupation  Annual Income\n",
      "0    21        Jamaica          Scholastic         100000\n",
      "1    28       Columbia               State          30000\n",
      "2    24           Cuba  University Teacher          40000\n",
      "3    23        Ecuador         Post Office          50000\n",
      "4    28         Canada              Police          20000\n",
      "5    45       Portugal             Private          30000\n",
      "6    43        Ireland              Office          34000\n",
      "7    45          Japan              Police          60000\n",
      "8    27          Japan         Post Office          25000\n",
      "9    33  North America         Post Office          30000\n",
      "10   32    West Europe              Office          40000\n",
      "\n",
      "SPLIT\n",
      "   Age     Birthplace   Occupation  Annual Income\n",
      "4   28         Canada       Police          20000\n",
      "9   33  North America  Post Office          30000\n",
      "\n",
      "SPLIT\n",
      "   Age Birthplace          Occupation  Annual Income\n",
      "2   24       Cuba  University Teacher          40000\n",
      "0   21    Jamaica          Scholastic         100000\n",
      "\n",
      "SPLIT\n",
      "   Age Birthplace   Occupation  Annual Income\n",
      "3   23    Ecuador  Post Office          50000\n",
      "1   28   Columbia        State          30000\n",
      "\n",
      "SPLIT\n",
      "   Age Birthplace   Occupation  Annual Income\n",
      "7   45      Japan       Police          60000\n",
      "8   27      Japan  Post Office          25000\n",
      "\n",
      "SPLIT\n",
      "    Age   Birthplace Occupation  Annual Income\n",
      "6    43      Ireland     Office          34000\n",
      "10   32  West Europe     Office          40000\n",
      "5    45     Portugal    Private          30000\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"Data/data.csv\")\n",
    "print(dataset)\n",
    "split_dataset = split(dataset)\n",
    "for d in split_dataset:\n",
    "    print(\"\\nSPLIT\")\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Age     Birthplace  Occupation  Annual Income\n",
      "4   [28-33]  North America       State          20000\n",
      "9   [28-33]  North America       State          30000\n",
      "2   [21-24]  North America  Scholastic          40000\n",
      "0   [21-24]  North America  Scholastic         100000\n",
      "3   [23-28]  South America       State          50000\n",
      "1   [23-28]  South America       State          30000\n",
      "7   [27-45]      East Asia       State          60000\n",
      "8   [27-45]      East Asia       State          25000\n",
      "6   [32-45]    West Europe     Private          34000\n",
      "10  [32-45]    West Europe     Private          40000\n",
      "5   [32-45]    West Europe     Private          30000\n"
     ]
    }
   ],
   "source": [
    "final_dataset = anonymize(split_dataset)\n",
    "print(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.sort_index().to_csv(\"Data/anonymized_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
